{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a915a83-59af-4676-9bdf-a718591c8dd0",
   "metadata": {},
   "source": [
    "# Use Tensorboard to visualize models, data and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69c22136-4c3b-4e91-969f-85dc1e26ba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82a61ff-9d92-4b6b-8202-7f86db46856b",
   "metadata": {},
   "source": [
    "## 1.Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ff396f5-605a-4354-870b-69167bf803b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('./data', download=True,\n",
    "                                             train=True, transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.FashionMNIST('./data', download=True,\n",
    "                                             train=False, transform=transform)\n",
    "# dataloaders\n",
    "batch_size = 4\n",
    "num_workers = 2\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=num_workers)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c623f626-df64-4556-8857-01821af6075e",
   "metadata": {},
   "source": [
    "**show the images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fe27d75-2a17-45f1-b250-d66e5e90474b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74582e2e-cada-4c13-94da-460e5db31505",
   "metadata": {},
   "source": [
    "<br />\n",
    "\n",
    "## 2.Define the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efedb6b2-38f0-4f9f-a12a-28bcace07a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af84a0a2-124d-48a1-8865-7a629a110572",
   "metadata": {},
   "source": [
    "<br />\n",
    "\n",
    "## 3.Define Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "835127c0-a95c-4d69-817b-c93716e266a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad4b6a3-b14c-4131-a590-4f4e40f8727c",
   "metadata": {},
   "source": [
    "<br />\n",
    "\n",
    "## 4.Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f150185-18e8-44fd-b4bd-32bfe85178a6",
   "metadata": {},
   "source": [
    "### 4.1.Tensorboard setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb04d220-e03e-4d56-b450-f0cb84b3c458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# key object for writing information to TensorBoard\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')  # default `log_dir` is \"runs\" - we'll be more specific here\n",
    "# Note that this line alone creates a `runs/fashion_mnist_experiment_1 folder`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114181f2-a1af-450a-8a67-ce9192d2f0b5",
   "metadata": {},
   "source": [
    "### 4.2.Writing to Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa6027af-d4e4-46a7-8a9c-5990e988f2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48be999c-57d0-4f9b-8ff0-afe6e91e47c1",
   "metadata": {},
   "source": [
    "### 4.3.Inspect the model using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "137ab47c-c53a-4a87-9d4b-654ee6753a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mxx/miniconda3/envs/deeplearning/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
